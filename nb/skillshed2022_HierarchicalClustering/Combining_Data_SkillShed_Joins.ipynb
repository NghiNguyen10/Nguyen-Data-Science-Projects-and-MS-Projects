{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b8311de",
   "metadata": {},
   "source": [
    "## Combining DataFrames for Joining: SkillShed Analysis\n",
    "\n",
    "### Author: Nghi Nguyen\n",
    "\n",
    "### Agenda\n",
    "\n",
    "\n",
    "1. File and Directory Navigation Commands\n",
    "2. Reading DataFrames from Python Script\n",
    "3. Performing Joins on DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aae096bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import getcwd, listdir, chdir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "782dbbfb",
   "metadata": {},
   "source": [
    "### 1. File and Directory Navigation Commands\n",
    "\n",
    "- ``getcwd()``\n",
    "\n",
    "This command is used to get the current working directory. Equivalent of using the `pwd` command in a Terminal or Command Line Interface (CLI).\n",
    "\n",
    "- ``chdir()``\n",
    "\n",
    "This command is used to change the current working directory by navigating to the directory mentioned in the input to the function. Equivalent of ``cd`` in Terminal or Command Line Interface (CLI).\n",
    "\n",
    "- ``listdir()``\n",
    "\n",
    "This command is used to list the contents of the directory specified as input to the function. Equivalent of ``ls`` on MacOS and ``dir`` on Windows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fad449cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "chdir(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a6db4bd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Volumes/SGD3/DS/Python/Pathrise/Fellows/Nghi/Pathrise_Nghi_Coding_Tutorials/src'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "00da678b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['event_driven_programming', 'nb', 'sas_to_pandas']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "listdir(getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1840c170",
   "metadata": {},
   "outputs": [],
   "source": [
    "chdir(\"sas_to_pandas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "81846343",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Volumes/SGD3/DS/Python/Pathrise/Fellows/Nghi/Pathrise_Nghi_Coding_Tutorials/src/sas_to_pandas'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0233b87c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['4_df_join.py',\n",
       " 'cleaned_data_euclidean_distance.py',\n",
       " 'cleaned_data_join.py',\n",
       " 'cleaned_data_occupations_of_interest.py',\n",
       " 'cleaned_data_wage_table.py',\n",
       " 'cleaning_raw_data.py',\n",
       " 'col_remover.py',\n",
       " 'dummy_data.py',\n",
       " 'euclidean_distance.py',\n",
       " 'knowledge_wide_exploration.py',\n",
       " 'occupations_of_interest.py',\n",
       " 'pandas_join_example.py',\n",
       " 'pandas_transform.py',\n",
       " 'scratchpad',\n",
       " 'wage_table.py',\n",
       " '__pycache__']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current = getcwd()\n",
    "listdir(current)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2161487",
   "metadata": {},
   "source": [
    "### 2. Reading DataFrames from Python Script\n",
    "\n",
    "In this section, we'll change the current working directory to be the parent directory of the GitHub repository in order to see the data and the Python scripts for rendering pandas DataFrames for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a7818929",
   "metadata": {},
   "outputs": [],
   "source": [
    "chdir(\"../..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ef6e6c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = getcwd() + \"/data/sas_to_pandas/raw/wages\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8e0bc126",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['OH_OEWS_21.csv', 'raw', 'Wages_Table_Final.csv']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "listdir(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "77d8bded",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.sas_to_pandas.cleaning_raw_data import knowledge_wide, work_activity_wide, work_context_wide, job_zones_2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f37b45af",
   "metadata": {},
   "source": [
    "### 3. Performing Joins on DataFrames\n",
    "\n",
    "In this section, we utilize the above DataFrames and join them together into a single DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "00937747",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Merge Function\n",
    "def merge_frames(frames: list, cols_to_join=['SOC_Code']) -> type(knowledge_wide):\n",
    "    # Join the DataFrames\n",
    "    result = frames[0]\n",
    "    for i in range(1, len(frames)):\n",
    "        result = result.merge(frames[i], on=['SOC_Code'], how='inner')\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "# Duplicate Filter Function\n",
    "def find_duplicate_cols(df):\n",
    "    # Find Duplicate Columns\n",
    "    duplicate_cols = []\n",
    "\n",
    "    for col in df.columns.tolist():\n",
    "        if '_x' in col:\n",
    "            duplicate_cols.append(col)\n",
    "        elif '__x' in col:\n",
    "            duplicate_cols.append(col)\n",
    "        elif '_y' in col:\n",
    "            duplicate_cols.append(col)\n",
    "        elif '__y' in col:\n",
    "            duplicate_cols.append(col)\n",
    "        else:\n",
    "            continue\n",
    "    return duplicate_cols\n",
    "\n",
    "# Keep the Title column\n",
    "def create_col(df, col: str):\n",
    "\n",
    "    # Find all columns that contain your input col string\n",
    "    cols = [elem for elem in df.columns.tolist() if col in elem]\n",
    "\n",
    "    # Secondary DataFrame\n",
    "    secondary_df = df[cols]\n",
    "\n",
    "    # Rename Columns\n",
    "    secondary_df.columns = [f\"col_{i+1}\" for i in range(secondary_df.shape[1])]\n",
    "\n",
    "    # Generate a Series of Cardinality Values for the Above Columns\n",
    "    cardinality_series = secondary_df.nunique()\n",
    "\n",
    "    # Choose the record that has the maximum value for cardinality\n",
    "    cardinality_record = cardinality_series[cardinality_series == max(cardinality_series.values)]\n",
    "\n",
    "    # Select the col corresponding to the above record\n",
    "    selected_col = cardinality_record.index[0]\n",
    "\n",
    "    # Save the Series from the above col\n",
    "    saved_series = secondary_df[selected_col]\n",
    "\n",
    "    # Remove the cols\n",
    "    df.drop(cols, axis=1, inplace=True)\n",
    "\n",
    "    # Create the new column\n",
    "    df[col] = saved_series.tolist()\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "92069e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting Frame Order\n",
    "## Joins\n",
    "frame_order = [knowledge_wide, work_activity_wide, work_context_wide, job_zones_2]\n",
    "\n",
    "# Applying the Functions\n",
    "result_df = create_col(merge_frames(frame_order), 'Title')\n",
    "\n",
    "## Reorder the Columns\n",
    "result_cols = ['SOC_Code', 'Title'] + sorted(result_df.columns.tolist()[1:-1])\n",
    "result_df = result_df[result_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b25a2766",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(873, 134)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chanr_community",
   "language": "python",
   "name": "chanr_community"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
